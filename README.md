내가 하려  했던 것

주행하는 차량의 전방 영상을 가지고 주변 차량을 인식할 수 있게 하고 싶었음



사용한 데이터 셋 원본

AI-hub : 승용 자율주행차 주간 자동차 전용도로 데이터
AI-hub : 승용 자율주행차 야간 자동차 전용도로 데이터(차후)
class_names = ["pedestrian", "trafficLight", "trafficSign", "twoWheeler", "vehicle"]

youtube에서 영상을 다운받아 학습시킨 모델을 올려서 테스트를 해봄

원본 영상 - (여수~순천 자동차전용도로 주행영상(From Yeosu to Suncheon)드라이브영상
		)https://www.youtube.com/watch?v=9waclbX5YOI&t=373s


데이터 셋에서의 문제점 :

	야간 데이터의 bbox(x1, y1, x2, y2)의 라벨링이 제대로 되어 있지 않았음
	라벨 데이터는 segmentation을 위한 polygon 데이터 라벨도 같이 제공 되었기에
	차라리 polygon을 bbox 형식으로 변환해보았더니 괜찮게 박스가 쳐졌음


우선 첫번째 학습과 두번째 학습을 비교해보면

첫째 학습에서는 파일 압축을 모두 풀지 못한 상태에서 진행했어서 10000장의 데이터를 학습시켰고
두번째 학습에서는 전체 파일에서 균형있게 데이터를 가져와 13000장을 구성하여 학습

두 학습 모두 


1. 대략 10000장의 주간 데이터를 학습, 11n 모델 150 epoch

	1) 주간에서 영상 인식이 잘 되는가
	2) 터널에서 영상 인식이 잘 되는가
	3) 야간 영상에서 영상 인식이 잘 되는가 ---> 데이터 증강이 필요해 보임


1. 11n 모델을 150 epoch 학습하고 나서 (주간영상만 포함)
	
	1) tunnel ---> 데이터셋에 터널이 꽤 있었기 때문에 터널 안에서 전방 차량 인식이 잘 됨
	2) day ---> 주간 자동차 전용도로 데이터셋과 비슷한 주행 영상으로 차량과 trafficsign을 잘 잡았음
	3) night ---> 야간에서도 vehicle을 어느정도 잘 잡았지만, 쓸데 없는 곳에 박스가 쳐지는 경우가 있었고, trafficsign을 제대로 잡지 못했음

	150 epoch 학습을 시켰는데 mAP가 0.5, n모델에서도 mAP가 낮았던 이유가 무엇일까 생각해보면 데이터 분포도가 주로 vehicle과 trafficsign에 몰빵 되어 심한 불균형이 있었음
   	자동차 주행 도로 환경에서는, 교통 표지판과 차량이 주를 이루기 떄문에
	이후 학습에서는 "pedestrian", "trafficLight", "twoWheeler" 을 제외한 vehicle과 trafficsign만으로 학습을 진행할 것.


3. 11m 모델을 이용하여 16000장의 주간영상 데이터를 사용

	처음 때 데이터셋에서 모든 데이터를 활용한게 아니라, 압축을 제대로 풀지 못했어서 모든 날, 시간대의 데이터를 골고루 사용하지 못했었고, 특정 시간대, 날짜의 데이터를 많이 사용해서 데이터셋을 구성했었음
	이번에는 train 데이터 압축을 잘 해제하고 다양한 주간(낮) 시간대의 영상을 균형있게 가져와 데이터셋을 구성함

	실행 결과 ---> 낮 데이터는 잘 잡음, 근데 모델의 크기 때문인지 영상 재생 속도가 너무 느림

	n 모델에서 대상을 박스칠 때 간혹 깜빡깜빡 거리는 경우가 있었는데 m 모델에서는 꽤 향상되었음
	같은 방향으로 주행하고 있는 차량은 n모델과 다를 바 없이 잘 잡았음
	반대 방향으로 주행하고 있는 차량을 잡는데 있어 n모델보다 조금 나은 모습은 보이긴 했으나, 완벽하게 잡아내지는 못했음
 	
4. 11s 모델을 밤 데이터 200 epoch
	
	n 모델과 m모델을 비교했을 때 학습 지표를 봤을 땐, 계속 큰 모델을 가지고 학습하고 싶었지만,
	실제로 영상프레임을 읽어오며 model을 적용 했을 땐 m모델이 n모델보다는 사이즈가 크기 때문에 영상이 0.7배정도로 눈에 확연하게 느리게 재생되었음
	실제 차량에다 적용한다고 생각했을 때, 모델이 빠르게 적용되는가도 중요한 평가지표라 생각 되어서 이번엔 m모델보단 사이즈가 작은 s모델을 학습 시켜봤음

	첫번쨰와 두번째 모델을 야간 영상에 적용해봤을 때, 탐지를 아에 못하는건 아니었음, 하지만 박스의 크기가 왔다갔다하거나, 박스가 깜빡깜빡 하고, 이상한 곳에 쳐진다는 문제가 있었음
	야간 영상을 잘 탐지하기 위해선 영상을 담은 데이터 셋을 넣어야 겠다 생각함


5. 학습을 통해 느낀점

 세 학습 모두 같은 방향으로 주행하는 차량은 잘 잡았지만, 반대 방향으로 주행하는 차량을 잡는데 한계가 있었습니다.
 아무래도 데이터 셋 자체가 차량의 전방 이미지다보니, 같은 방향으로 진행하는 차량에 포커스가 맞춰 있기 때문이 아니었나 싶음
 
 터널을 들어가고 나올 때 앞에 가던 차량을 놓쳐버리는 현상이 계속 나왔는데 이는 따로 해결 방법이 필요해 보임 
	
 --> 라이다(레이저 기반 센서)를 이용하면 주변 밝기에 영향을 받지 않을 수 있음
	Multi-target Tracking(MTT) 여러 대상을 동시에 추적하면서 앞차가 일시적으로 시야에서 사라지더라도, 그 위치를 예측하여 차량을 계속 추적 가능
	Kalman Filter(칼만 필터 사용) 물체의 현재 상태를 기반으로 미래 상태를 예측

이처럼 차량을 탐지하는 것에서 더 나아가 차선 인식, 차량간의 거리 계산, 차량 추적, 차량의 움직임 예측, 
라이다, 레이더, 카메라 등 다양한 센서를 융합한 인지 등 다양한 기술이 있기에
최종프로젝트 전까지 준비를 잘해서 최종프로젝트 때는 현재 자율주행 인지에 적용되는 기술을 직접 구현해보고 싶다는 목표가 생겼습니다.

mAP와/ precision보다 recall이 낮은 이유


recall : 실제 객체를 얼마나 놓치지 않고 탐지했나?

모델이 특정 클래스나 객체를 잘 탐지하지 못할 때도 Recall이 낮아질 수 있습니다. 
이는 학습 데이터가 불충분하거나 불균형한 경우, 또는 특정 클래스에 대한 학습이 잘 이루어지지 않았을 때 발생합니다.































